Most important right now is to refactor the code.
The renderer should just be responsible for making a renderpass.
The differents subpasses will be in different classes, making their own pipeline and stuff.
The renderer will then just make the renderpass, start the frame, call each subpass then do cmdnextsubpass.

Subpasses:
- glTF renderer / PBR
- Voxelization
- ImGUI

So each subclasses will have:
    - Specific descriptor sets
    - Shaders
    - Pipeline

Maybe each sublclass will have its own index vertex.

The renderer will have:
   - Global descriptor sets (needed?)
   - Render pass
   - Swapchain
   - Frame resources

* glTF
- Maybe move the index and vertex buffer from the renderer to the model as each model has a different set of vertices.

* Voxel Cone Tracing

Everything has to be done in the GPU in order to have real-time performance.

** Voxelization

Technique:
- No render target / Discard the results.
- Vertex input is the geometry

- Vertex shader ::
     - Do a orthogonal projection of the size of the voxels grid
     - Pass data to the geometry shader

- Geometry shader ::
     - Find the best orientation for the voxel

- Fragment shader ::
     - Convert the fragment to a voxel
     - Add it to the voxel list which is a atomic storage buffer

Debug:
- Vertex input is the voxels
- Vertex shader: Do usual thing
- Geometry shader: if the voxel is not empty expand it to a cube
- Fragment shader: Set the color to the voxel color

Works but slow for now...

** First bounce
** Second bounce
** Use voxels to cone trace
